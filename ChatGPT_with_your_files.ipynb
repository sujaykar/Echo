{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujaykar/Echo/blob/main/ChatGPT_with_your_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Requirement"
      ],
      "metadata": {
        "id": "0l3MD3312Itl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You might need to reinstall Pillow library if you receive PIL error\n",
        "# !pip uninstall Pillow\n",
        "# !pip install --upgrade Pillow\n",
        "# import PIL\n",
        "# print(PIL.__version__)"
      ],
      "metadata": {
        "id": "zxvS6Afa_RI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WI5qfkUe0Q0"
      },
      "outputs": [],
      "source": [
        "!pip install openai -q\n",
        "!pip install langchain -q\n",
        "!pip install chromadb -q\n",
        "!pip install tiktoken -q\n",
        "!pip install pypdf -q\n",
        "!pip install unstructured[local-inference] -q\n",
        "!pip install gradio -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "TgkUctQX2Pbg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUTbnXkHe6Rv"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your OpenAI Key Here\"\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature=0,model_name=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Da3yPddNjxY"
      },
      "source": [
        "# Load your data into Reports folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSxialfUTh9b",
        "outputId": "2a2f5cf4-b6ab-4bc2-cef8-5ff20c906383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of documents: 3\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "pdf_loader = DirectoryLoader('./Reports/', glob=\"**/*.pdf\")\n",
        "txt_loader = DirectoryLoader('./Reports/', glob=\"**/*.txt\")\n",
        "word_loader = DirectoryLoader('./Reports/', glob=\"**/*.docx\")\n",
        "\n",
        "loaders = [pdf_loader, txt_loader, word_loader]\n",
        "documents = []\n",
        "for loader in loaders:\n",
        "    documents.extend(loader.load())\n",
        "\n",
        "print(f\"Total number of documents: {len(documents)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34HYlsekNona"
      },
      "source": [
        "# Chunk the data, turn into Embeddings and save to VectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aUybd6KhN7F"
      },
      "outputs": [],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
        "documents = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptdb1wVuNzom"
      },
      "source": [
        "# Calling the Langchain's QA chain with Chat History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEBWBa1nhQwV"
      },
      "outputs": [],
      "source": [
        "qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4okS40zMrLIL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKmAxuY9rqxK"
      },
      "source": [
        "# Gradio Chat UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "SAJVCq7Sly5Y",
        "outputId": "5643bf66-4316-4d2d-b2a8-224b97ce9145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User query: You were given three documents as context\n",
            "Chat history: []\n",
            "Updated chat history: [('You were given three documents as context', 'Yes, that is correct. The first document appears to be a speech about the state of the union, the second document seems to be a list of updates and features for various Microsoft products, and the third document mentions a change in estimated useful lives of servers and network equipment. Is there anything specific you would like me to help you with?')]\n",
            "User query: Summarize each documents for me\n",
            "Chat history: [['You were given three documents as context', 'Yes, that is correct. The first document appears to be a speech about the state of the union, the second document seems to be a list of updates and features for various Microsoft products, and the third document mentions a change in estimated useful lives of servers and network equipment. Is there anything specific you would like me to help you with?']]\n",
            "Updated chat history: [['You were given three documents as context', 'Yes, that is correct. The first document appears to be a speech about the state of the union, the second document seems to be a list of updates and features for various Microsoft products, and the third document mentions a change in estimated useful lives of servers and network equipment. Is there anything specific you would like me to help you with?'], ('Summarize each documents for me', \"Sure, here's a summary of each document:\\n\\n1. The first document is a transcript of a conference call where Google executives discussed the company's financial results and plans for the future. They talked about ongoing work that will impact the company's performance in 2023 and 2024, as well as changes to the estimated useful lives of servers and network equipment that will positively impact operating results in 2023.\\n\\n2. The second document is a transcript of another conference call where Google executives discussed the company's efforts to bring AI products to market with integrity and principles, without sacrificing quality or trust. They also talked about the company's strong business momentum in areas like Cloud, YouTube subscriptions, and Hardware, but acknowledged that revenues were impacted by pullbacks in advertiser spend and foreign exchange.\\n\\n3. The third document is a statement from a Google executive about the company's efforts to make YouTube the best place for Shorts and creators. They mentioned a new revenue sharing program for Shorts creators and emphasized their focus on making YouTube a great platform for short-form video content.\")]\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "# Define chat interface\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.Button(\"Clear\")\n",
        "    chat_history = []\n",
        "\n",
        "    def user(query, chat_history):\n",
        "        print(\"User query:\", query)\n",
        "        print(\"Chat history:\", chat_history)\n",
        "\n",
        "        # Convert chat history to list of tuples\n",
        "        chat_history_tuples = []\n",
        "        for message in chat_history:\n",
        "            chat_history_tuples.append((message[0], message[1]))\n",
        "\n",
        "        # Get result from QA chain\n",
        "        result = qa({\"question\": query, \"chat_history\": chat_history_tuples})\n",
        "\n",
        "        # Append user message and response to chat history\n",
        "        chat_history.append((query, result[\"answer\"]))\n",
        "        print(\"Updated chat history:\", chat_history)\n",
        "\n",
        "        return gr.update(value=\"\"), chat_history\n",
        "\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False)\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}